{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wADwK78DCz"
      },
      "source": [
        "# Proyek Analisis Data: [Brazilian E-Commerce Public Dataset by Olist]\n",
        "- **Nama:** Yunico Ardian Pradana\n",
        "- **Email:** yunicoardian123@gmail.com\n",
        "- **ID Dicoding: yunicoardian** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE0raob58DC0"
      },
      "source": [
        "## Menentukan Pertanyaan Bisnis\n",
        "- Pertanyaan 1 : Negara bagian mana saja yang memiliki pendapatan tertinggi?\n",
        "- Pertanyaan 2 : Bagaimana Trend Pendapatan/Pemasukan di 5 negara dengan revenue tertinggi ?\n",
        "- Pertanyaan 3 : Produk apa saja yang menjadi sumber pendapatan terbesar di lima negara bagian tersebut ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-z4QGlO8DC1"
      },
      "source": [
        "## Import Semua Packages/Library yang Digunakan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FVYwaObI8DC1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Sh51Xy8DC1"
      },
      "source": [
        "## Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXU2GBYu8DC1"
      },
      "source": [
        "### Gathering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zjCBk1BI8DC1"
      },
      "outputs": [],
      "source": [
        "# read zip\n",
        "zip_file = zipfile.ZipFile('archive.zip', 'r')\n",
        "# extract zip to new folder\n",
        "zip_file.extractall('datasets/')\n",
        "# close zipfile\n",
        "zip_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca Dataframe customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>customer_unique_id</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>customer_city</th>\n",
              "      <th>customer_state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
              "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
              "      <td>14409</td>\n",
              "      <td>franca</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
              "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
              "      <td>9790</td>\n",
              "      <td>sao bernardo do campo</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
              "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
              "      <td>1151</td>\n",
              "      <td>sao paulo</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
              "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
              "      <td>8775</td>\n",
              "      <td>mogi das cruzes</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
              "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
              "      <td>13056</td>\n",
              "      <td>campinas</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id                customer_unique_id  \\\n",
              "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
              "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
              "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
              "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
              "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
              "\n",
              "   customer_zip_code_prefix          customer_city customer_state  \n",
              "0                     14409                 franca             SP  \n",
              "1                      9790  sao bernardo do campo             SP  \n",
              "2                      1151              sao paulo             SP  \n",
              "3                      8775        mogi das cruzes             SP  \n",
              "4                     13056               campinas             SP  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_customer = pd.read_csv('datasets/olist_customers_dataset.csv')\n",
        "df_customer.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca Dataframe geolocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>geolocation_zip_code_prefix</th>\n",
              "      <th>geolocation_lat</th>\n",
              "      <th>geolocation_lng</th>\n",
              "      <th>geolocation_city</th>\n",
              "      <th>geolocation_state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1037</td>\n",
              "      <td>-23.545621</td>\n",
              "      <td>-46.639292</td>\n",
              "      <td>sao paulo</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1046</td>\n",
              "      <td>-23.546081</td>\n",
              "      <td>-46.644820</td>\n",
              "      <td>sao paulo</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1046</td>\n",
              "      <td>-23.546129</td>\n",
              "      <td>-46.642951</td>\n",
              "      <td>sao paulo</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1041</td>\n",
              "      <td>-23.544392</td>\n",
              "      <td>-46.639499</td>\n",
              "      <td>sao paulo</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1035</td>\n",
              "      <td>-23.541578</td>\n",
              "      <td>-46.641607</td>\n",
              "      <td>sao paulo</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
              "0                         1037       -23.545621       -46.639292   \n",
              "1                         1046       -23.546081       -46.644820   \n",
              "2                         1046       -23.546129       -46.642951   \n",
              "3                         1041       -23.544392       -46.639499   \n",
              "4                         1035       -23.541578       -46.641607   \n",
              "\n",
              "  geolocation_city geolocation_state  \n",
              "0        sao paulo                SP  \n",
              "1        sao paulo                SP  \n",
              "2        sao paulo                SP  \n",
              "3        sao paulo                SP  \n",
              "4        sao paulo                SP  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_geolocation = pd.read_csv('datasets/olist_geolocation_dataset.csv')\n",
        "df_geolocation.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca Dataframe order_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>order_item_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>shipping_limit_date</th>\n",
              "      <th>price</th>\n",
              "      <th>freight_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
              "      <td>1</td>\n",
              "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
              "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
              "      <td>2017-09-19 09:45:35</td>\n",
              "      <td>58.90</td>\n",
              "      <td>13.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
              "      <td>1</td>\n",
              "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
              "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
              "      <td>2017-05-03 11:05:13</td>\n",
              "      <td>239.90</td>\n",
              "      <td>19.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
              "      <td>1</td>\n",
              "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
              "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
              "      <td>2018-01-18 14:48:30</td>\n",
              "      <td>199.00</td>\n",
              "      <td>17.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00024acbcdf0a6daa1e931b038114c75</td>\n",
              "      <td>1</td>\n",
              "      <td>7634da152a4610f1595efa32f14722fc</td>\n",
              "      <td>9d7a1d34a5052409006425275ba1c2b4</td>\n",
              "      <td>2018-08-15 10:10:18</td>\n",
              "      <td>12.99</td>\n",
              "      <td>12.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>\n",
              "      <td>1</td>\n",
              "      <td>ac6c3623068f30de03045865e4e10089</td>\n",
              "      <td>df560393f3a51e74553ab94004ba5c87</td>\n",
              "      <td>2017-02-13 13:57:51</td>\n",
              "      <td>199.90</td>\n",
              "      <td>18.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           order_id  order_item_id  \\\n",
              "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
              "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
              "2  000229ec398224ef6ca0657da4fc703e              1   \n",
              "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
              "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
              "\n",
              "                         product_id                         seller_id  \\\n",
              "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
              "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
              "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
              "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
              "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
              "\n",
              "   shipping_limit_date   price  freight_value  \n",
              "0  2017-09-19 09:45:35   58.90          13.29  \n",
              "1  2017-05-03 11:05:13  239.90          19.93  \n",
              "2  2018-01-18 14:48:30  199.00          17.87  \n",
              "3  2018-08-15 10:10:18   12.99          12.79  \n",
              "4  2017-02-13 13:57:51  199.90          18.14  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_order_items = pd.read_csv('datasets/olist_order_items_dataset.csv')\n",
        "df_order_items.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca Dataframe order_payments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>payment_sequential</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>payment_installments</th>\n",
              "      <th>payment_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b81ef226f3fe1789b1e8b2acac839d17</td>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>8</td>\n",
              "      <td>99.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a9810da82917af2d9aefd1278f1dcfa0</td>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>1</td>\n",
              "      <td>24.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>1</td>\n",
              "      <td>65.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ba78997921bbcdc1373bb41e913ab953</td>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>8</td>\n",
              "      <td>107.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42fdf880ba16b47b59251dd489d4441a</td>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>2</td>\n",
              "      <td>128.45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           order_id  payment_sequential payment_type  \\\n",
              "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
              "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
              "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
              "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
              "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
              "\n",
              "   payment_installments  payment_value  \n",
              "0                     8          99.33  \n",
              "1                     1          24.39  \n",
              "2                     1          65.71  \n",
              "3                     8         107.78  \n",
              "4                     2         128.45  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_order_payments = pd.read_csv('datasets/olist_order_payments_dataset.csv')\n",
        "df_order_payments.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca Dataframe order_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>order_id</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_comment_title</th>\n",
              "      <th>review_comment_message</th>\n",
              "      <th>review_creation_date</th>\n",
              "      <th>review_answer_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
              "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-01-18 00:00:00</td>\n",
              "      <td>2018-01-18 21:46:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
              "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-03-10 00:00:00</td>\n",
              "      <td>2018-03-11 03:05:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
              "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-02-17 00:00:00</td>\n",
              "      <td>2018-02-18 14:36:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
              "      <td>658677c97b385a9be170737859d3511b</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recebi bem antes do prazo estipulado.</td>\n",
              "      <td>2017-04-21 00:00:00</td>\n",
              "      <td>2017-04-21 22:02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
              "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
              "      <td>2018-03-01 00:00:00</td>\n",
              "      <td>2018-03-02 10:26:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          review_id                          order_id  \\\n",
              "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
              "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
              "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
              "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
              "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
              "\n",
              "   review_score review_comment_title  \\\n",
              "0             4                  NaN   \n",
              "1             5                  NaN   \n",
              "2             5                  NaN   \n",
              "3             5                  NaN   \n",
              "4             5                  NaN   \n",
              "\n",
              "                              review_comment_message review_creation_date  \\\n",
              "0                                                NaN  2018-01-18 00:00:00   \n",
              "1                                                NaN  2018-03-10 00:00:00   \n",
              "2                                                NaN  2018-02-17 00:00:00   \n",
              "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
              "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
              "\n",
              "  review_answer_timestamp  \n",
              "0     2018-01-18 21:46:59  \n",
              "1     2018-03-11 03:05:13  \n",
              "2     2018-02-18 14:36:24  \n",
              "3     2017-04-21 22:02:06  \n",
              "4     2018-03-02 10:26:53  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_order_reviews = pd.read_csv('datasets/olist_order_reviews_dataset.csv')\n",
        "df_order_reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca Dataframe orders_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>order_status</th>\n",
              "      <th>order_purchase_timestamp</th>\n",
              "      <th>order_approved_at</th>\n",
              "      <th>order_delivered_carrier_date</th>\n",
              "      <th>order_delivered_customer_date</th>\n",
              "      <th>order_estimated_delivery_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
              "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-10-02 10:56:33</td>\n",
              "      <td>2017-10-02 11:07:15</td>\n",
              "      <td>2017-10-04 19:55:00</td>\n",
              "      <td>2017-10-10 21:25:13</td>\n",
              "      <td>2017-10-18 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
              "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2018-07-24 20:41:37</td>\n",
              "      <td>2018-07-26 03:24:27</td>\n",
              "      <td>2018-07-26 14:31:00</td>\n",
              "      <td>2018-08-07 15:27:45</td>\n",
              "      <td>2018-08-13 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
              "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2018-08-08 08:38:49</td>\n",
              "      <td>2018-08-08 08:55:23</td>\n",
              "      <td>2018-08-08 13:50:00</td>\n",
              "      <td>2018-08-17 18:06:29</td>\n",
              "      <td>2018-09-04 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
              "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-11-18 19:28:06</td>\n",
              "      <td>2017-11-18 19:45:59</td>\n",
              "      <td>2017-11-22 13:39:59</td>\n",
              "      <td>2017-12-02 00:28:42</td>\n",
              "      <td>2017-12-15 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
              "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2018-02-13 21:18:39</td>\n",
              "      <td>2018-02-13 22:20:29</td>\n",
              "      <td>2018-02-14 19:46:34</td>\n",
              "      <td>2018-02-16 18:17:02</td>\n",
              "      <td>2018-02-26 00:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           order_id                       customer_id  \\\n",
              "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
              "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
              "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
              "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
              "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
              "\n",
              "  order_status order_purchase_timestamp    order_approved_at  \\\n",
              "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
              "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
              "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
              "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
              "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
              "\n",
              "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
              "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
              "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
              "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
              "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
              "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
              "\n",
              "  order_estimated_delivery_date  \n",
              "0           2017-10-18 00:00:00  \n",
              "1           2018-08-13 00:00:00  \n",
              "2           2018-09-04 00:00:00  \n",
              "3           2017-12-15 00:00:00  \n",
              "4           2018-02-26 00:00:00  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_orders_dataset = pd.read_csv('datasets/olist_orders_dataset.csv')\n",
        "df_orders_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca Dataframe products_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_category_name</th>\n",
              "      <th>product_name_lenght</th>\n",
              "      <th>product_description_lenght</th>\n",
              "      <th>product_photos_qty</th>\n",
              "      <th>product_weight_g</th>\n",
              "      <th>product_length_cm</th>\n",
              "      <th>product_height_cm</th>\n",
              "      <th>product_width_cm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
              "      <td>perfumaria</td>\n",
              "      <td>40.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
              "      <td>artes</td>\n",
              "      <td>44.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
              "      <td>esporte_lazer</td>\n",
              "      <td>46.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cef67bcfe19066a932b7673e239eb23d</td>\n",
              "      <td>bebes</td>\n",
              "      <td>27.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9dc1a7de274444849c219cff195d0b71</td>\n",
              "      <td>utilidades_domesticas</td>\n",
              "      <td>37.0</td>\n",
              "      <td>402.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>625.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         product_id  product_category_name  \\\n",
              "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
              "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
              "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
              "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
              "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
              "\n",
              "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
              "0                 40.0                       287.0                 1.0   \n",
              "1                 44.0                       276.0                 1.0   \n",
              "2                 46.0                       250.0                 1.0   \n",
              "3                 27.0                       261.0                 1.0   \n",
              "4                 37.0                       402.0                 4.0   \n",
              "\n",
              "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
              "0             225.0               16.0               10.0              14.0  \n",
              "1            1000.0               30.0               18.0              20.0  \n",
              "2             154.0               18.0                9.0              15.0  \n",
              "3             371.0               26.0                4.0              26.0  \n",
              "4             625.0               20.0               17.0              13.0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_products_dataset = pd.read_csv('datasets/olist_products_dataset.csv')\n",
        "df_products_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca Dataframe sellers_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seller_id</th>\n",
              "      <th>seller_zip_code_prefix</th>\n",
              "      <th>seller_city</th>\n",
              "      <th>seller_state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
              "      <td>13023</td>\n",
              "      <td>campinas</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
              "      <td>13844</td>\n",
              "      <td>mogi guacu</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
              "      <td>20031</td>\n",
              "      <td>rio de janeiro</td>\n",
              "      <td>RJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
              "      <td>4195</td>\n",
              "      <td>sao paulo</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
              "      <td>12914</td>\n",
              "      <td>braganca paulista</td>\n",
              "      <td>SP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          seller_id  seller_zip_code_prefix  \\\n",
              "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
              "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
              "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
              "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
              "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
              "\n",
              "         seller_city seller_state  \n",
              "0           campinas           SP  \n",
              "1         mogi guacu           SP  \n",
              "2     rio de janeiro           RJ  \n",
              "3          sao paulo           SP  \n",
              "4  braganca paulista           SP  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sellers_dataset = pd.read_csv('datasets/olist_sellers_dataset.csv')\n",
        "df_sellers_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baca product category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_category_name</th>\n",
              "      <th>product_category_name_english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beleza_saude</td>\n",
              "      <td>health_beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>informatica_acessorios</td>\n",
              "      <td>computers_accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>automotivo</td>\n",
              "      <td>auto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cama_mesa_banho</td>\n",
              "      <td>bed_bath_table</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moveis_decoracao</td>\n",
              "      <td>furniture_decor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    product_category_name product_category_name_english\n",
              "0            beleza_saude                 health_beauty\n",
              "1  informatica_acessorios         computers_accessories\n",
              "2              automotivo                          auto\n",
              "3         cama_mesa_banho                bed_bath_table\n",
              "4        moveis_decoracao               furniture_decor"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_product_name = pd.read_csv('datasets/product_category_name_translation.csv')\n",
        "df_product_name.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHSiqaZp8DC1"
      },
      "source": [
        "### Assessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store dataframes in a list\n",
        "dataframes = [df_customer, df_geolocation, df_order_items, df_order_payments, df_order_reviews, df_orders_dataset, df_products_dataset, df_sellers_dataset, df_product_name]\n",
        "\n",
        "for df in dataframes:\n",
        "    # Get the variable name using globals()\n",
        "    df_name = [name for name, obj in globals().items() if obj is df][0]\n",
        "    print(f\"\\nCustom Info for {df_name} dataframe:\")\n",
        "    print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selanjutnya kita mencoba untuk melihat jumlah Null Value pada tiap dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in dataframes:\n",
        "    # Get the variable name using globals()\n",
        "    df_name = [name for name, obj in globals().items() if obj is df][0]\n",
        "    \n",
        "    print(f\"\\nMissing Values in {df_name} dataframe:\")\n",
        "    print(df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "selanjutnya kita cek juga duplikat pada tiap dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in dataframes:\n",
        "    # Get the variable name using globals()\n",
        "    df_name = [name for name, obj in globals().items() if obj is df][0]\n",
        "    print(f\"\\nTotal baris duplikat pada {df_name} dataframe: {df.duplicated().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "selanjutnya check distribusi data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in dataframes:\n",
        "    # Get the variable name using globals()\n",
        "    df_name = [name for name, obj in globals().items() if obj is df][0]\n",
        "    \n",
        "    print(f\"\\nDistribusi data pada {df_name} :\")\n",
        "    print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders_dataset.order_status.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhN5R4hr8DC1"
      },
      "source": [
        "### Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pada saat kita check duplikat terlihat bahwa di dataframe df_geolocation terdapat duplikat sejumlah 261831 sehingga perlu penanganan lebih lanjut dengan cara menghapus diplikat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVnYpprE9Evz"
      },
      "outputs": [],
      "source": [
        "df_geolocation.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "setelah kita menghapus duplikat, cek kembali untuk memastikan tidak ada duplikat "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocation.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "selanjutnya ialah kita check null value pada dataframe df_order_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_order_reviews.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hasil diatas menunjukkan kolom review_comment_title dan review_comment_message terdapat nilai null value, maka langkah selanjutnya ialah kita melakukan imputasi atau menambahkan nilai default string \"No Tittle\" dan \"No Message\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_order_reviews[\"review_comment_message\"].fillna(\"No Message\", inplace=True)\n",
        "df_order_reviews[\"review_comment_title\"].fillna(\"No Title\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pada saat kita assessing data, terdapat beberapa kolom yang seharusnya tipe datanya datetime malah obj/str. oleh karena itu kita perlu mengubahnya kedalah format datetime. beberapa kolom yang memerlukan perubahan ada di dataset df_orders_dataset, df_order_reviews, dan df_order_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_order_items['shipping_limit_date'] = pd.to_datetime(df_order_items['shipping_limit_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orders_column = [\n",
        "    'order_delivered_carrier_date', \n",
        "    'order_delivered_customer_date', \n",
        "    'order_estimated_delivery_date', \n",
        "    'order_purchase_timestamp', \n",
        "    'order_approved_at'\n",
        "]\n",
        "\n",
        "for column in orders_column:\n",
        "    df_orders_dataset[column] = pd.to_datetime(df_orders_dataset[column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "col123 = ['review_creation_date', 'review_answer_timestamp']\n",
        "df_order_reviews[col123] = df_order_reviews[col123].apply(pd.to_datetime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp-Y6wU38DC1"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pertanyaan No 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hanya pesanan yang telah dikirim yang akan digunakan dalam analisis berikut.\n",
        "df_orders123 = df_orders_dataset[df_orders_dataset['order_status'] == 'delivered'] # Pilih pesanan dengan status terkirim\n",
        "df_orders123 = df_orders123.reset_index(drop = True) # Mengatur ulang indeks kolom\n",
        "\n",
        "# Dalam analisis berikut ini ada 4 kolom yang akan digunakan dari tabel orders: \n",
        "# order_id, customer_id, order_status, order_purchase_timestamp\n",
        "\n",
        "kolom_yang_dihapus = ['order_approved_at','order_delivered_carrier_date', 'order_delivered_customer_date', \n",
        "'order_estimated_delivery_date']\n",
        "df_orders123 = df_orders123.drop(kolom_yang_dihapus, axis=1)\n",
        "\n",
        "df_orders123['order_purchase_timestamp'] = pd.to_datetime(df_orders123['order_purchase_timestamp'])\n",
        "df_orders123.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gabungkan dataframe df_orders123 dan df, lalu simpan di dataframe revenue_states\n",
        "revenue_states = pd.merge(df_orders123, df_customer, how='left', on='customer_id')\n",
        "\n",
        "# Gabungkan dataframe revenue_states dan payments table, then stored in revenue_states\n",
        "revenue_states = pd.merge(revenue_states, df_order_payments, how='left', on='order_id')\n",
        "revenue_states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ubah singkatan yang ada pada kolom customer_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kamus untuk mengganti singkatan dengan nama lengkap\n",
        "state_mapping = {\n",
        "    'AC': 'Acre',\n",
        "    'AL': 'Alagoas',\n",
        "    'AM': 'Amazonas',\n",
        "    'AP': 'Amapa',\n",
        "    'BA': 'Bahia',\n",
        "    'CE': 'Ceara',\n",
        "    'DF': 'Distrito Federal',\n",
        "    'ES': 'Espirito Santo',\n",
        "    'GO': 'Goias',\n",
        "    'MA': 'Maranhao',\n",
        "    'MG': 'Minas Gerais',\n",
        "    'MS': 'Mato Grosso do Sul',\n",
        "    'MT': 'Mato Grosso',\n",
        "    'PA': 'Para',\n",
        "    'PB': 'Paraiba',\n",
        "    'PE': 'Pernambuco',\n",
        "    'PI': 'Piaui',\n",
        "    'PR': 'Parana',\n",
        "    'RJ': 'Rio de Janeiro',\n",
        "    'RN': 'Rio Grande do Norte',\n",
        "    'RO': 'Rondonia',\n",
        "    'RR': 'Roraima',\n",
        "    'RS': 'Rio Grande do Sul',\n",
        "    'SC': 'Santa Catarina',\n",
        "    'SE': 'Sergipe',\n",
        "    'SP': 'Sao Paulo',\n",
        "    'TO': 'Tocantins'\n",
        "}\n",
        "\n",
        "# Mengganti singkatan dengan nama lengkap menggunakan map\n",
        "revenue_states['customer_state'] = revenue_states['customer_state'].map(state_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "revenue_states.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "revenue_states[revenue_states.isna().any(axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Karena hanya ada 4 nilai yang hilang dalam 1 baris dari 100757 baris, menghapus satu baris tidak akan mempengaruhi analisis secara signifikan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "revenue_states = revenue_states.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# From table 1, group by 'customer_state' and sum the 'payment_value' for each state\n",
        "revenue_by_state = revenue_states.groupby('customer_state')['payment_value'].sum().reset_index()\n",
        "\n",
        "# Sort the summary by highest revenue in descending order\n",
        "revenue_by_state = revenue_by_state.sort_values(by='payment_value', ascending=False)\n",
        "revenue_by_state.columns = ['State', 'Revenue']\n",
        "revenue_by_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pertanyaan No 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "di pertanyaan ke 2 ini kita ingin melihat trend revenue per bulan dari tahun 2016 hingga 2018 di 5 kota dengan revenue tertinggi. adapun implementasinya ada pada kode dibawah"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_monthly_revenue(revenue_states, state_column, states=None):\n",
        "    if states:\n",
        "        revenue_states = revenue_states[revenue_states[state_column].isin(states)]\n",
        "\n",
        "    revenue_states['year'] = revenue_states['order_purchase_timestamp'].dt.year\n",
        "    revenue_states['month'] = revenue_states['order_purchase_timestamp'].dt.month\n",
        "    group_columns = ['year', 'month']\n",
        "    if state_column in revenue_states.columns:\n",
        "        group_columns.append(state_column)\n",
        "    monthly_revenue = revenue_states.groupby(group_columns)['payment_value'].sum().reset_index()\n",
        "    monthly_revenue = monthly_revenue.sort_values(by=[state_column, 'year', 'month']).reset_index(drop=True)\n",
        "    monthly_revenue['year_month'] = monthly_revenue['year'].astype(str) + '-' + monthly_revenue['month'].astype(str)\n",
        "    monthly_revenue.columns = ['year', 'month', 'state', 'revenue', 'year_month']\n",
        "    return monthly_revenue\n",
        "\n",
        "# Calculate monthly revenue for specific states\n",
        "states_to_calculate = ['Sao Paulo', 'Rio de Janeiro', 'Minas Gerais', 'Rio Grande do Sul', 'Parana']\n",
        "monthly_revenue_states = {}\n",
        "for state in states_to_calculate:\n",
        "    monthly_revenue_states[state] = calculate_monthly_revenue(revenue_states, 'customer_state', states=[state])\n",
        "\n",
        "# Access the results\n",
        "monthly_revenue_SP = monthly_revenue_states['Sao Paulo']\n",
        "monthly_revenue_RJ = monthly_revenue_states['Rio de Janeiro']\n",
        "monthly_revenue_MG = monthly_revenue_states['Minas Gerais']\n",
        "monthly_revenue_RS = monthly_revenue_states['Rio Grande do Sul']\n",
        "monthly_revenue_PR = monthly_revenue_states['Parana']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "monthly_revenue_SP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pertanyaan No 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "pada pertanyaan no 3, kita ingin melihat produk apa saja yang menjadi sumber pendapatan dari 5 negara bagian tersebut. prosesnya melibatkan beberapa penggabungan dataset. adapun implementasinya ada pada kode dibawah ini "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge df_products_dataset table and df_product_name table, stored in products_merged\n",
        "products_merged = pd.merge(df_products_dataset, df_product_name, how='left', on='product_category_name')\n",
        "\n",
        "# Merge revenue_states table and df_order_items table, stored in revenue_order_items\n",
        "revenue_order_items = pd.merge(revenue_states, df_order_items, how='left', on='order_id')\n",
        "\n",
        "# Merge revenue_order_items table and products_merged table, stored in revenue_order_items\n",
        "revenue_products = pd.merge(revenue_order_items, products_merged, how='left', on='product_id')\n",
        "\n",
        "revenue_products.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "revenue_products = revenue_products.rename(columns={'product_category_name_english': 'product_category'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "revenue_products = revenue_products[['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'customer_state', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value', 'product_id', 'product_category']]\n",
        "revenue_products.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_values = revenue_products.isna().sum().reset_index().rename(columns={'index': 'column_name', 0: 'value'})\n",
        "missing_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kl = revenue_products[revenue_products.isna().any(axis=1)]\n",
        "kl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "karena banyak sekali data yang missing value, disini saya memutuskan untuk menghapus baris data dimana category bernilai NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "revenue_products = revenue_products.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# menampilkan baris yang duplikat\n",
        "revenue_products[revenue_products.duplicated(keep=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing duplicates values\n",
        "revenue_products = revenue_products.drop_duplicates(keep='first') # Remove duplicate data and keep the first data that appears\n",
        "revenue_products = revenue_products.reset_index(drop = True) # Reset the column index\n",
        "revenue_products.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_revenue_per_product_cat(revenue_data, state_list):\n",
        "    revenue_by_state = {}\n",
        "    \n",
        "    for state in state_list:\n",
        "        state_data = revenue_data[revenue_data['customer_state'] == state]\n",
        "        revenue_by_state[state] = state_data.groupby('product_category')['payment_value'].sum().reset_index()\n",
        "        \n",
        "    return revenue_by_state\n",
        "\n",
        "def calculate_revenue_proportion(revenue_by_state_dict, state):\n",
        "    state_summary = revenue_by_state_dict.get(state)\n",
        "\n",
        "    if state_summary is not None:\n",
        "        state_summary['revenue_proportion'] = (state_summary['payment_value'] / state_summary['payment_value'].sum()) * 100\n",
        "    \n",
        "    return state_summary.rename(columns={'payment_value': 'revenue', 'revenue_proportion': 'revenue_proportion'})\n",
        "\n",
        "def sort_by_revenue(revenue_summary, ascending=True):\n",
        "    return revenue_summary.sort_values(by='revenue', ascending=ascending).head(10).reset_index(drop=True)\n",
        "\n",
        "# Top 5 states with highest revenue\n",
        "states = ['Sao Paulo', 'Rio de Janeiro', 'Minas Gerais', 'Rio Grande do Sul', 'Parana']\n",
        "\n",
        "# Calculate revenue per product category for top 5 states\n",
        "revenue_by_state_dict = calculate_revenue_per_product_cat(revenue_products, states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage for sorting by highest revenue\n",
        "state = 'Sao Paulo'\n",
        "state_summary = calculate_revenue_proportion(revenue_by_state_dict, state)\n",
        "highest_SP = sort_by_revenue(state_summary, ascending=False)\n",
        "highest_SP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state = 'Rio de Janeiro'\n",
        "state_summary = calculate_revenue_proportion(revenue_by_state_dict, state)\n",
        "highest_RJ = sort_by_revenue(state_summary, ascending=False)\n",
        "highest_RJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state = 'Minas Gerais'\n",
        "state_summary = calculate_revenue_proportion(revenue_by_state_dict, state)\n",
        "highest_MG = sort_by_revenue(state_summary, ascending=False)\n",
        "highest_MG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state = 'Rio Grande do Sul'\n",
        "state_summary = calculate_revenue_proportion(revenue_by_state_dict, state)\n",
        "highest_RS = sort_by_revenue(state_summary, ascending=False)\n",
        "highest_RS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state = 'Parana'\n",
        "state_summary = calculate_revenue_proportion(revenue_by_state_dict, state)\n",
        "highest_PR = sort_by_revenue(state_summary, ascending=False)\n",
        "highest_PR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsyZjqak8DC2"
      },
      "source": [
        "## Visualization & Explanatory Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZxOiQ6n8DC2"
      },
      "source": [
        "### Pertanyaan 1:\n",
        "Negara bagian mana saja yang memiliki pendapatan tertinggi?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create viz1 dataframe for visualization of revenue by state \n",
        "viz1 = revenue_by_state\n",
        "\n",
        "# Create the visualization of revenue by state\n",
        "fig = px.bar(data_frame=viz1, x='State', y='Revenue', title='Negara dengan Revenue Tertinggi')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgHI7CiU8DC2"
      },
      "source": [
        "### Pertanyaan 2: \n",
        "Bagaimana Trend Pendapatan/Pemasukan di 5 negara dengan revenue tertinggi ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0lCsvO8DC2"
      },
      "outputs": [],
      "source": [
        "fig = make_subplots(rows=3, cols=2, subplot_titles=('Revenue Trend Sao Paulo', 'Revenue Trend Rio de Janeiro', \n",
        "'Revenue Trend Minas Gerais', 'Revenue Trend Rio Grande do Sul', 'Revenue Trend Parana'))\n",
        "\n",
        "# Add Plotly Express plots to each subplot\n",
        "fig.add_trace(px.line(monthly_revenue_SP, x='year_month', y='revenue').data[0], row=1, col=1)\n",
        "fig.add_trace(px.line(monthly_revenue_RJ, x='year_month', y='revenue').data[0], row=1, col=2)\n",
        "fig.add_trace(px.line(monthly_revenue_MG, x='year_month', y='revenue').data[0], row=2, col=1)\n",
        "fig.add_trace(px.line(monthly_revenue_RS, x='year_month', y='revenue').data[0], row=2, col=2)\n",
        "fig.add_trace(px.line(monthly_revenue_PR, x='year_month', y='revenue').data[0], row=3, col=1)\n",
        "\n",
        "# Update subplot titles (optional)\n",
        "fig.update_layout(title_text='Trend Revenue di 5 Negara Bagian',\n",
        "                  autosize=False,\n",
        "                  width=1000,\n",
        "                  height=1200,)\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pertanyaan 3: \n",
        "Produk apa saja yang menjadi sumber pendapatan terbesar di lima negara bagian tersebut ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "\n",
        "# Daftar summary dan judul subplot\n",
        "summaries = [highest_SP, highest_RJ, highest_MG, highest_RS, highest_PR]\n",
        "titles = ['Sumber Pendapatan tertinggi Sao Paulo', 'Sumber Pendapatan tertinggi Rio de Janeiro', 'Sumber Pendapatan tertinggi Minas Gerais',\n",
        "          'Sumber Pendapatan tertinggi Rio Grande do Sul', 'Sumber Pendapatan tertinggi Parana']\n",
        "\n",
        "# Membuat subplot\n",
        "fig = make_subplots(rows=3, cols=2, subplot_titles=titles)\n",
        "\n",
        "# Menambahkan Plotly Express plots ke setiap subplot\n",
        "for i, summary in enumerate(summaries):\n",
        "    row = i // 2 + 1  # Hitung baris subplot\n",
        "    col = i % 2 + 1   # Hitung kolom subplot\n",
        "    fig.add_trace(px.bar(summary, x='product_category', y='revenue').data[0], row=row, col=col)\n",
        "\n",
        "# Memperbarui layout\n",
        "fig.update_layout(title_text='Sumber Pendapatan terbesar di 5 Negara dengan Revenue Tertinggi',\n",
        "                  autosize=False,\n",
        "                  width=1000,\n",
        "                  height=1200)\n",
        "\n",
        "# Menampilkan plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WeHlCeX8DC2"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTcyR48Y8DC2"
      },
      "source": [
        "Negara dengan revenue/pendapatan tertinggi jika diurutkan *descending* adalah Sao Paulo, Rio de Janeiro, Minas Gerais, Rio Grande de Sul, Parana."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pendapatan di negara bagian Sao Paulo, Rio de Janeiro, Minas Gerais, Rio Grande do Sul, dan Parana menunjukkan tren positif yang cenderung naik secara fluktuatif mulai dari bulan Oktober 2016 hingga Agustus 2018"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sumber pendapatan tertinggi di negara bagian Sao Paulo, Rio de Janeiro, Minas Gerais, Rio Grande do Sul adalah bed_bath_table sedangkan di negara bagian Parana pendapatan tertinggi ada di furniture_decor"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "972b3bf27e332e87b5379f2791f6ef9dfc79c71018c370b0d7423235e20fe4d7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
